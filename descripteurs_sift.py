# -*- coding: utf-8 -*-
"""Descripteurs_SIFT.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1-BTQy3tbVPDktgMiNAfddC2CIpQoPTqF
"""

#Nous importons nos bibiliothèques utiles
import os
import random
from scipy import spatial
from tqdm import tqdm
import time
import seaborn as sn
import math
import cv2
import numpy as np
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split

import pandas as pd
from sklearn.metrics import confusion_matrix, classification_report

# Nous allons convertir nos images en niveau de gris
def convertToGray(images):
    grayImages = [0] * images.shape[0]
    for i, img in enumerate(images):
        grayImages[i] = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)
    return np.array(grayImages)

# Recherche des index des K plus grande valeur de matches sous forme de score
def getMaxIndex(tab, d_match, k, trainLabels):
    countScores = [0] * k
    labels = [0] * k
    dm = [0] * k
    index_s = [0] * k

    for i in range(k):
        m = max(tab)
        index = tab.index(m)
        countScores[i] = round(m, 2)
        labels[i] = trainLabels[index]
        dm[i] = d_match[index]
        index_s[i] = index
        tab[index] = -1

    return np.array(list(zip(labels, countScores, dm, index_s)))

# Fonction de prédiction de l'image à partir des descripteurs
def descriptorsPredictions(desc, descriptors_train, trainLabels, threshold, k):
    sc, d_match = nbrMatch(descriptors_train, desc, threshold)
    p = getMaxIndex(sc, d_match, k, trainLabels)
    (objects, qte) = np.unique([i[0] for i in p], return_counts=True)
    arg = list(zip(objects, qte))
    arg = sorted(arg, key=lambda item: item[1], reverse=True)

    # We search for the predicted object with the highest score
    obj = arg[0][0]
    p = sorted(p, key=lambda item: item[1], reverse=True)
    # We return the first found
    for find in p:
        if obj == find[0]:
            return find

#Téléchargement du dataset
import gdown 
url = "https://drive.google.com/uc?id=1rwVyzK2oJg1iEd84wQ08geXwY6OzprwN"
out = "coil-100.zip"
gdown.download(url, out, quiet=False)

!unzip coil-100.zip

#Nous chargeons nos images
imagesPath = 'coil-100/'
imagesList = [ f for f in os.listdir(imagesPath) if os.path.isfile(os.path.join(imagesPath,f)) ]

imagesObj = []
labeslObj = []

for img in imagesList:
  #Nous devons nous assurer que le fichier traité est une image
    if img.split('.')[1] == 'png':
        image = cv2.imread(os.path.join(imagesPath, img))
        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)
        imagesObj.append(image)
        #Pour calculer le nombre de classes que nous avons
        labeslObj.append(img.split('__')[0])

#Nous allons transformer nos images en des arrays numpy    
imagesObj = np.array(imagesObj)
labeslObj = np.array(labeslObj)
print('{} images chargées avec succès'.format(imagesObj.shape[0]))

#Affichage de quelques labels
print(labeslObj)

#Fonction pour l'affichage des resultats
def showResults(figsize, imagesArray, size):
  plt.figure(figsize=figsize)
  for k, i in np.ndenumerate(np.random.randint(imagesArray.shape[0], size=size)):
      ax = plt.subplot(4, 4, k[0] + 1)
      plt.imshow(imagesArray[i], cmap='gray')
      plt.title('Image N° {}'.format(i))
      plt.axis("off")

showResults((10,10), imagesObj, 8)

print("Nombre total de classes dans notre dataset : ", len(np.unique(labeslObj)))

#Utilisation de la fonction train_test_split de  learn pour avoir nos données d'entrainement et de test 
#avec le random_state=42 pour avoir les memes données divisées à chaque éxécution
trainImages, testImages, trainLabels, testLabels = train_test_split(imagesObj, labeslObj, test_size=0.3, random_state=42)

grayTrainImages = convertToGray(trainImages)

grayTestImages = convertToGray(testImages)

showResults((10,10), grayTrainImages, 8)

# Fonction pour calculer les descripteurs locaux pour chaque image
def calculateDescriptors(images, grayImages):
    sift = cv2.xfeatures2d.SIFT_create()
    descriptors = [0] * images.shape[0]
    keypoints = [0] * images.shape[0]
    keypointsList = [0] * images.shape[0]
    
    for i, img in enumerate(grayImages):
        kp, des = sift.detectAndCompute(img, None)
        descriptors[i] = des
        keypoints[i] = cv2.drawKeypoints(img, kp, images[i].copy(), flags = cv2.DRAW_MATCHES_FLAGS_DRAW_RICH_KEYPOINTS)
        keypointsList[i] = kp
        
    return np.array(descriptors), np.array(keypoints), np.array(keypointsList)

trainDescriptors, trainKPImages, trainKP = calculateDescriptors(trainImages, grayTrainImages)

testDescriptors, testKPImages, testKP = calculateDescriptors(testImages, grayTestImages)

showResults((10,10), np.array(trainKPImages), 8)

#Nous allons enregistrer nos descripteurs dans des fichiers
np.save('descriptors.npy', trainDescriptors)
np.save('labels.npy', trainLabels)

#Relecture des fichiers enregistrés si l'on veut utiliser pour ne pas reprendre depuis le début
oldDescriptors = np.load('descriptors.npy', allow_pickle=True)
oldLabels = np.load('labels.npy', allow_pickle=True)

#fonction de verification du matching
def verifMatch(trainVectors, testVectors, THRESHOLD):
    keyTrainToTest = []
    
    if testVectors is not None:
        result = [None] * testVectors.shape[0]
        correspondance = 0

        tree = spatial.KDTree(trainVectors)

        euclDistance, index = tree.query(testVectors, p=2, k=2)

        for k, (dist, ind) in enumerate(zip(euclDistance, index)):

            ratio = dist[0] / dist[1]
            if ratio < THRESHOLD:
                tree_2 = spatial.KDTree(testVectors)

                euclDistance_2, index_2 = tree_2.query(trainVectors[ind[0]], p=2, k=2)

                ratio_2 = euclDistance_2[0] / euclDistance_2[1]
                if ratio_2 < THRESHOLD and index_2[0] == k:
                     
                    result[k] = trainVectors[ind[0]]
                    keyTrainToTest.append(cv2.DMatch(ind[0], index_2[0], euclDistance_2[0]))
                    correspondance += 1
                else:
                    result[k] = None
            else:
                result[k] = None

        return correspondance/trainVectors.shape[0], result, keyTrainToTest
    else:
        return 0, [], keyTrainToTest

"""Calcul du nombre de matches par classes sur les images d'entrainement"""

#Fonction de calcul de nombre de match
def nbrMatch(trainDesc, testDesc, THRESHOLD):
    result = []
    d_match = []

    for i, img in enumerate(trainDesc):
        dm = []
        if isinstance(img, type(None)):
            score = 0
        else:
            score, _, dm = verifMatch(img, testDesc, THRESHOLD)
        result.append(score)
        d_match.append(dm)

    return result, d_match

myScoreMatch = nbrMatch(trainDescriptors, testDescriptors[33], 0.6)

#classement par ordre décroissant des scores
print(np.sort(myScoreMatch[0])[::-1])

predict = getMaxIndex(myScoreMatch[0], myScoreMatch[1], 5, trainLabels)

print(predict)

#Nous affichons quelques résultats
illustration = []
for i in range(len(testImages[:10])):
  result = descriptorsPredictions(testDescriptors[i], trainDescriptors, trainLabels, 0.6, 5)
  other = cv2.drawMatches(trainImages[result[3]], trainKP[result[3]], testImages[i], testKP[i], result[2], None)
  illustration.append(other)
  
  #plt.imshow(illustration)

illustration = np.array(illustration)

showResults((20,15), illustration, 16)

# Evaluation

def evaluation(THRESHOLD, K = 5):
    predictions = [0] * testLabels.shape[0]
    with tqdm(total=testLabels.shape[0], desc="Prediction", bar_format="{l_bar}{bar} [ time left: {remaining} ]") as pbar:
        for i, des_test in enumerate(testDescriptors):
            predictions[i] = descriptorsPredictions(des_test, trainDescriptors, trainLabels, THRESHOLD, K)[0]
            pbar.update(1)
        
    return predictions

#évaluation sur toutes les images de train
predictionsLabels = evaluation(0.7, 5)
# Calcul du score
sum(predictionsLabels == testLabels) / testLabels.shape[0]

#A sauvegarder après le premier entrainement pour ne plus reprendre cela
predictLabelsToSave = np.array(predictionsLabels)
np.save('/content/drive/MyDrive/predictedLabels.npy', predictLabelsToSave)
np.save('/content/drive/MyDrive/testLabels.npy', testLabels)

#Téléchargement des fichiers enregistrés lors de l'évaluation pour ne pas perdre le temps
url = "https://drive.google.com/uc?id=1GNkKb57lQijr9FNqE42tsznUV4YmTFZd"
url2 = "https://drive.google.com/uc?id=1--wRY7z_d5u0cQn-qp0PER7wkGcZdDZy"
gdown.download(url, 'test.npy', quiet=False)
gdown.download(url2, 'predit.npy', quiet=False)

testLabelsFromDrive = np.load('test.npy', allow_pickle=True)
predictionLabelsFromDrive = np.load('predit.npy', allow_pickle=True)

#Matrice de confusion
confusionMatrix = confusion_matrix(testLabelsFromDrive, np.array(predictionLabelsFromDrive))

df_cm = pd.DataFrame(confusionMatrix, index = [i for i in np.unique(testLabelsFromDrive)],
              columns = [i for i in np.unique(testLabelsFromDrive)])

plt.figure(figsize = (30,30))
plt.title('Confusion Matrix', fontsize = 20)
sn.heatmap(df_cm, annot=True, cmap="gray_r", linewidths=.5)
plt.xlabel('Actual', fontsize = 15) 
plt.ylabel('Predicted', fontsize = 15) 
plt.show()

print(classification_report(testLabelsFromDrive, predictionLabelsFromDrive))

